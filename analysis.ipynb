{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.ctime()\n",
    "print(f\"Start:{now}\")\n",
    "with open(\"data/network_info/edges.json\", \"r\", encoding='utf-8') as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "graph = nx.Graph()\n",
    "\n",
    "print(\"building network ...\")\n",
    "for i, edge in enumerate(edges):\n",
    "    graph.add_edge(edge[0], edge[1])\n",
    "print(\"build network finish.\")\n",
    "\n",
    "\n",
    "print(\"runing community partition algorithm ...\")\n",
    "communities = nx_comm.louvain_communities(graph, seed=487)\n",
    "print(\"community partition algorithm finish.\")\n",
    "\n",
    "\n",
    "communities_info = {}\n",
    "nodes2community = {}\n",
    "for community_id, community in enumerate(communities):\n",
    "\n",
    "    community_edges = set()\n",
    "    for node_i in community:\n",
    "        neighbors = graph.neighbors(node_i)\n",
    "        for node_j in neighbors:\n",
    "            if node_j in community:\n",
    "                community_edges.add(\n",
    "                    (node_i, node_j) if node_i < node_j else (node_j, node_i)\n",
    "                )\n",
    "        nodes2community[node_i] = str(community_id)\n",
    "\n",
    "    communities_info[community_id] = {\n",
    "        \"edges\": list(community_edges),\n",
    "        \"member\": list(community)\n",
    "    }\n",
    "end = time.ctime()\n",
    "print(f\"End:{end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:Fri May 27 15:22:04 2022\n",
      "building network ...\n",
      "build network finish.\n"
     ]
    }
   ],
   "source": [
    "now = time.ctime()\n",
    "print(f\"Start:{now}\")\n",
    "with open(\"data/network_info/edges.json\", \"r\", encoding='utf-8') as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "graph = nx.Graph()\n",
    "\n",
    "print(\"building network ...\")\n",
    "for i, edge in enumerate(edges):\n",
    "    graph.add_edge(edge[0], edge[1])\n",
    "print(\"build network finish.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:Fri May 27 15:30:23 2022\n",
      "building network ...\n",
      "build network finish.\n",
      "1.7523047150480502 CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models\n",
      "1.5226620788169254 StereoSet: Measuring stereotypical bias in pretrained language models\n",
      "1.4267989942323336 Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP\n",
      "1.231390170529015 Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little\n",
      "1.1262623582090252 Recent Advances in Natural Language Processing via Large Pre-Trained  Language Models: A Survey\n",
      "0.9861223598916374 Unmasking the Mask - Evaluating Social Biases in Masked Language Models\n",
      "0.9357570330011152 X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models\n",
      "0.9034218451957557 Distilling the Knowledge of BERT for Sequence-to-Sequence ASR\n",
      "0.7558267942650961 Measuring Fairness with Biased Rulers: A Survey on Quantifying Biases in  Pretrained Language Models\n",
      "0.7190282611705302 An Empirical Survey of the Effectiveness of Debiasing Techniques for  Pre-trained Language Models\n"
     ]
    }
   ],
   "source": [
    "now = time.ctime()\n",
    "print(f\"Start:{now}\")\n",
    "with open(\"data/network_info/edges.json\", \"r\", encoding='utf-8') as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "graph = nx.Graph()\n",
    "\n",
    "print(\"building network ...\")\n",
    "for i, edge in enumerate(edges):\n",
    "    graph.add_edge(edge[0], edge[1])\n",
    "print(\"build network finish.\")\n",
    "\n",
    "title = \"Masked Language Model Scoring\"\n",
    "top_n = 10\n",
    "with open(\"data/network_info/title2semantic_scholar_id.json\", \"r\", encoding='utf-8') as f:\n",
    "    title2paper_id = json.load(f)\n",
    "query_paper_id = title2paper_id[title]\n",
    "\n",
    "query_edges = [(query_paper_id, other_paper) for other_paper \n",
    "        in graph[query_paper_id]]\n",
    "\n",
    "jc_preds = nx.jaccard_coefficient(graph, query_edges)\n",
    "aa_preds = nx.adamic_adar_index(graph, query_edges)\n",
    "# 將不同演算法預測結果整合\n",
    "mixed_preds = {}\n",
    "for preds in [jc_preds, aa_preds]:\n",
    "    for _, other_paper_id, score in preds:\n",
    "        if other_paper_id not in mixed_preds.keys(): \n",
    "            mixed_preds[other_paper_id] = score\n",
    "        else:\n",
    "            mixed_preds[other_paper_id] += score\n",
    "\n",
    "# 將預測結果排序並輸出\n",
    "mixed_preds = {k: v for k, v in sorted(mixed_preds.items(), key=lambda item: item[1], reverse=True)}\n",
    "mixed_preds_id = list(mixed_preds.keys())[:top_n]\n",
    "mixed_preds_score = list(mixed_preds.values())[:top_n]\n",
    "with open(\"data/network_info/semantic_scholar_id2title.json\", \"r\", encoding='utf-8') as f:\n",
    "    paper_id2title = json.load(f)\n",
    "mixed_preds_title = [paper_id2title[id] for id in mixed_preds_id]\n",
    "for title, score in zip(mixed_preds_title, mixed_preds_score):\n",
    "    print(score, title)\n",
    "end = time.ctime()\n",
    "print(f\"End:{end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f72311f06bc1a4fedb117aa7f45c9a623304697e97971975014b96fbf84ebb5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('earthquake')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
